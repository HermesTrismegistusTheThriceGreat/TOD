# Database Implementation Expertise
# Multi-Agent Orchestration System - PostgreSQL Architecture

overview:
  description: "PostgreSQL database layer using asyncpg for connection pooling and Pydantic for type-safe modeling"
  database_system: "PostgreSQL (NeonDB recommended)"
  driver: "asyncpg (asynchronous driver for asyncio)"
  orm_pattern: "Lightweight Pydantic models over raw SQL queries (No heavy ORM like SQLAlchemy)"
  schema_management: "Idempotent SQL migrations"

core_implementation:
  database_module:
    file: "apps/orchestrator_3_stream/backend/modules/database.py"
    lines: 1964
    purpose: "Connection pooling and database operations"

    connection_pool:
      lifecycle:
        init_pool: "Creates asyncpg.create_pool with min/max size config (line 34)"
        get_pool: "Returns existing pool or raises RuntimeError (line 67)"
        close_pool: "Gracefully closes all connections (line 82)"
        get_connection: "Context manager for acquiring connections from pool (line 96)"
      config:
        min_size: 5
        max_size: 20
        timeout: 60s

    query_patterns:
      - "Explicit transaction management (async with conn.transaction():)"
      - "Raw SQL with parameter substitution ($1, $2, etc.)"
      - "Return values mapped to Pydantic models or dictionaries"
      - "JSONB handling via json.dumps/loads"

  data_models:
    file: "apps/orchestrator_db/models.py"
    purpose: "Single source of truth for data structures"
    framework: "Pydantic V2"

    models:
      - "OrchestratorAgent: orchestrator_agents table"
      - "Agent: agents table"
      - "Prompt: prompts table"
      - "AgentLog: agent_logs table"
      - "SystemLog: system_logs table"
      - "OrchestratorChat: orchestrator_chat table"
      - "AiDeveloperWorkflow: ai_developer_workflows table"
      - "AlpacaOrder: alpaca_orders table"
      - "AlpacaPosition: alpaca_positions table"

    features:
      - "Automatic UUID conversion (asyncpg UUID <-> Python UUID)"
      - "Decimal to Float conversion for currency"
      - "JSON string parsing for metadata/payload fields"
      - "Datetime serialization to ISO format"
      - "Literal types for status enums"

    distribution:
      source: "apps/orchestrator_db/models.py"
      synced_to:
        - "apps/orchestrator_3_stream/backend/modules/orch_database_models.py"
      sync_script: "apps/orchestrator_db/sync_models.py"

  schema_migrations:
    directory: "apps/orchestrator_db/migrations/"
    runner: "apps/orchestrator_db/run_migrations.py"
    pattern: "Numbered SQL files (0_*.sql through 10_*.sql) executed in order"
    idempotency: "Uses 'CREATE TABLE IF NOT EXISTS' and 'CREATE INDEX IF NOT EXISTS'"
    files:
      - "0_orchestrator_agents.sql"
      - "1_agents.sql"
      - "2_prompts.sql"
      - "3_agent_logs.sql"
      - "4_system_logs.sql"
      - "5_indexes.sql"
      - "6_functions.sql"
      - "7_triggers.sql"
      - "8_orchestrator_chat.sql"
      - "9_ai_developer_workflows.sql"
      - "10_alpaca_orders.sql"

  alpaca_sync_service:
    file: "apps/orchestrator_3_stream/backend/modules/alpaca_sync_service.py"
    lines: 866
    purpose: "Syncs Alpaca order/position data to database with trade grouping"
    connection: "Separate asyncpg pool (min=2, max=10) using same DATABASE_URL"

schema_structure:
  logging_architecture:
    overview: "Separate logging tables for orchestrator vs command-level agents"
    orchestrator_logs: "Stored in orchestrator_chat table (FK: orchestrator_agent_id -> orchestrator_agents.id)"
    command_agent_logs: "Stored in agent_logs table (FK: agent_id -> agents.id)"
    system_logs: "Application-level logs only (no agent-specific activity)"
    key_distinction: "agent_logs references agents.id, NOT orchestrator_agents.id"

  tables:
    orchestrator_agents:
      description: "Singleton state for the main orchestrator"
      pk: "id (UUID)"
      unique: "session_id"
      fields:
        - "session_id (TEXT, nullable, UNIQUE): Claude SDK session identifier"
        - "system_prompt (TEXT): Orchestrator system prompt"
        - "status (TEXT): idle, executing, waiting, blocked, complete"
        - "working_dir (TEXT): Working directory path"
        - "input_tokens, output_tokens (INTEGER DEFAULT 0)"
        - "total_cost (DECIMAL(10,4) DEFAULT 0.0000)"
        - "archived (BOOLEAN DEFAULT false): Soft delete flag"
        - "metadata (JSONB DEFAULT '{}')"
        - "created_at, updated_at (TIMESTAMPTZ)"
      indexes:
        - "idx_orchestrator_agents_status"
        - "idx_orchestrator_agents_updated_at"
      logs_stored_in: "orchestrator_chat table"

    agents:
      description: "Registry of specialized sub-agents (command-level agents)"
      pk: "id (UUID)"
      fk: "orchestrator_agent_id -> orchestrator_agents.id ON DELETE CASCADE"
      unique: "(orchestrator_agent_id, name) - agent names unique per orchestrator"
      fields:
        - "name (TEXT NOT NULL)"
        - "model (TEXT NOT NULL): Claude model ID"
        - "system_prompt (TEXT)"
        - "working_dir (TEXT)"
        - "git_worktree (TEXT): Git worktree path if using worktrees"
        - "status (TEXT): idle, executing, waiting, blocked, complete"
        - "session_id (TEXT): Claude SDK session ID"
        - "adw_id (TEXT): AI Developer Workflow ID"
        - "adw_step (TEXT): ADW step identifier"
        - "input_tokens, output_tokens (INTEGER DEFAULT 0)"
        - "total_cost (DECIMAL(10,4) DEFAULT 0.0000)"
        - "archived (BOOLEAN DEFAULT false)"
        - "metadata (JSONB DEFAULT '{}')"
        - "created_at, updated_at (TIMESTAMPTZ)"
      indexes:
        - "idx_agents_status"
        - "idx_agents_archived"
        - "idx_agents_updated_at"
        - "idx_agents_name"
      logs_stored_in: "agent_logs table"

    agent_logs:
      description: "Event stream for COMMAND-LEVEL AGENTS ONLY. FK references agents.id"
      pk: "id (UUID)"
      fk: "agent_id -> agents.id ON DELETE CASCADE"
      important: "Orchestrator logs go to orchestrator_chat, not here"
      fields:
        - "agent_id (UUID NOT NULL)"
        - "session_id (TEXT): Claude SDK session ID"
        - "task_slug (TEXT): Task identifier (kebab-case)"
        - "adw_id (TEXT): AI Developer Workflow identifier"
        - "adw_step (TEXT): ADW step identifier"
        - "entry_index (INTEGER): Sequential index for tail reading"
        - "event_category (TEXT NOT NULL): hook, response, adw_step"
        - "event_type (TEXT NOT NULL): PreToolUse, PostToolUse, text, thinking, tool_use, tool_result"
        - "content (TEXT): Primary text content"
        - "payload (JSONB DEFAULT '{}'): Structured event data"
        - "summary (TEXT): AI-generated summary"
        - "timestamp (TIMESTAMPTZ DEFAULT NOW())"
      indexes:
        - "idx_agent_logs_agent_id"
        - "idx_agent_logs_task_slug (partial)"
        - "idx_agent_logs_adw_id, idx_agent_logs_adw_step (partial)"
        - "idx_agent_logs_task_index (composite)"
        - "idx_agent_logs_category, idx_agent_logs_type"
        - "idx_agent_logs_category_type (composite)"
        - "idx_agent_logs_timestamp"
        - "idx_agent_logs_session (partial)"

    orchestrator_chat:
      description: "3-way communication: user ↔ orchestrator ↔ agents"
      pk: "id (UUID)"
      fk:
        - "orchestrator_agent_id -> orchestrator_agents.id ON DELETE CASCADE"
        - "agent_id -> agents.id ON DELETE CASCADE (nullable)"
      constraint: "agent_id required when sender_type or receiver_type is 'agent'"
      fields:
        - "orchestrator_agent_id (UUID NOT NULL)"
        - "sender_type (TEXT NOT NULL): user, orchestrator, agent"
        - "receiver_type (TEXT NOT NULL): user, orchestrator, agent"
        - "message (TEXT NOT NULL)"
        - "summary (TEXT): AI-generated summary"
        - "agent_id (UUID, nullable): Required when sender/receiver is agent"
        - "metadata (JSONB DEFAULT '{}')"
        - "created_at, updated_at (TIMESTAMPTZ)"
      indexes:
        - "idx_orchestrator_chat_orch_id"
        - "idx_orchestrator_chat_agent_id"
        - "idx_orchestrator_chat_sender_type"
        - "idx_orchestrator_chat_receiver_type"
        - "idx_orchestrator_chat_orch_created (composite)"
        - "idx_orchestrator_chat_agent_created (composite)"

    prompts:
      description: "History of prompts sent to agents"
      pk: "id (UUID)"
      fk: "agent_id -> agents.id ON DELETE CASCADE (nullable)"
      fields:
        - "agent_id (UUID, nullable)"
        - "task_slug (TEXT)"
        - "author (TEXT NOT NULL): engineer, orchestrator_agent"
        - "prompt_text (TEXT NOT NULL)"
        - "summary (TEXT)"
        - "timestamp (TIMESTAMPTZ DEFAULT NOW())"
        - "session_id (TEXT)"
      indexes:
        - "idx_prompts_agent_id"
        - "idx_prompts_author"
        - "idx_prompts_timestamp"
        - "idx_prompts_task_slug (partial)"

    system_logs:
      description: "Application-level logs ONLY (global events, no agent-specific activity)"
      pk: "id (UUID)"
      important: "Agent logs go to agent_logs or orchestrator_chat, not here"
      fields:
        - "file_path (TEXT)"
        - "adw_id (TEXT)"
        - "adw_step (TEXT)"
        - "level (TEXT NOT NULL): DEBUG, INFO, WARNING, ERROR"
        - "message (TEXT NOT NULL)"
        - "summary (TEXT)"
        - "metadata (JSONB DEFAULT '{}')"
        - "timestamp (TIMESTAMPTZ DEFAULT NOW())"
      indexes:
        - "idx_system_logs_level"
        - "idx_system_logs_timestamp"
        - "idx_system_logs_adw_id, idx_system_logs_adw_step (partial)"

    ai_developer_workflows:
      description: "Tracks ADW executions (id serves as adw_id in agent_logs/system_logs)"
      pk: "id (UUID)"
      fk: "orchestrator_agent_id -> orchestrator_agents.id ON DELETE CASCADE"
      fields:
        - "adw_name (TEXT NOT NULL): Workflow name (e.g., 'feature-auth')"
        - "workflow_type (TEXT NOT NULL): Workflow type from adw_*.py filename"
        - "description (TEXT)"
        - "status (TEXT): pending, in_progress, completed, failed, cancelled"
        - "current_step (TEXT): Current step slug"
        - "total_steps, completed_steps (INTEGER)"
        - "started_at, completed_at (TIMESTAMPTZ)"
        - "duration_seconds (INTEGER)"
        - "input_data, output_data (JSONB)"
        - "error_message, error_step (TEXT), error_count (INTEGER)"
        - "metadata (JSONB)"
      indexes:
        - "idx_adw_orchestrator, idx_adw_status, idx_adw_workflow_type"
        - "idx_adw_created (DESC)"
        - "idx_adw_active (partial: status IN pending, in_progress)"

    alpaca_orders:
      description: "Alpaca order history with trade grouping for multi-leg strategies"
      pk: "id (UUID)"
      unique: "alpaca_order_id"
      key_concept: "trade_id links related orders (same underlying + expiry + 5min window)"
      fields:
        - "alpaca_order_id (TEXT NOT NULL UNIQUE): Alpaca's UUID"
        - "trade_id (UUID NOT NULL): Groups related orders together"
        - "strategy_type (TEXT): iron_condor, vertical_spread, strangle, straddle, single_leg, options"
        - "leg_number (INTEGER): 1-4 for iron condors"
        - "symbol (TEXT NOT NULL): OCC option symbol (e.g., SPY260117C00688000)"
        - "underlying (TEXT NOT NULL): Ticker (SPY, QQQ)"
        - "side (TEXT): buy, sell"
        - "qty, filled_qty (DECIMAL)"
        - "order_type (TEXT): market, limit, stop, stop_limit"
        - "limit_price, stop_price, filled_avg_price (DECIMAL)"
        - "status (TEXT): new, filled, canceled, expired, etc."
        - "expiry_date (DATE), strike_price (DECIMAL), option_type (TEXT): call, put"
        - "submitted_at, filled_at, expired_at, canceled_at (TIMESTAMPTZ)"
        - "raw_data (JSONB)"
      indexes:
        - "idx_alpaca_orders_trade_id, idx_alpaca_orders_symbol, idx_alpaca_orders_underlying"
        - "idx_alpaca_orders_status, idx_alpaca_orders_strategy"
        - "idx_alpaca_orders_submitted (DESC), idx_alpaca_orders_filled (DESC)"
        - "idx_alpaca_orders_trade_underlying (composite)"

    alpaca_positions:
      description: "Current open positions from Alpaca with trade linking"
      pk: "id (UUID)"
      constraint: "UNIQUE (symbol, is_open)"
      fields:
        - "trade_id (UUID, nullable): Links to related orders"
        - "symbol (TEXT NOT NULL): OCC option symbol"
        - "underlying (TEXT NOT NULL)"
        - "qty (DECIMAL), side (TEXT): long, short"
        - "avg_entry_price, current_price, market_value, cost_basis (DECIMAL)"
        - "unrealized_pl, unrealized_plpc (DECIMAL): P/L dollars and percentage"
        - "expiry_date (DATE), strike_price (DECIMAL), option_type (TEXT)"
        - "is_open (BOOLEAN DEFAULT TRUE)"
        - "raw_data (JSONB)"
      indexes:
        - "idx_alpaca_positions_trade_id, idx_alpaca_positions_symbol"
        - "idx_alpaca_positions_underlying, idx_alpaca_positions_is_open"

key_operations:
  orchestrator_management:
    get_or_create:
      function: "get_or_create_orchestrator (line 122)"
      logic: "Returns existing active orchestrator or creates new one"

    create_new:
      function: "create_new_orchestrator (line 186)"
      logic: "Creates new orchestrator with initial values"

    get:
      function: "get_orchestrator (line 238)"
      logic: "Returns active orchestrator (archived=false) or None"

    get_by_session:
      function: "get_orchestrator_by_session (line 265)"
      logic: "Look up orchestrator by Claude SDK session_id"

    get_by_id:
      function: "get_orchestrator_by_id (line 298)"
      logic: "Look up orchestrator by UUID"

    session_update:
      function: "update_orchestrator_session (line 329)"
      logic: "Updates session_id only if current value is NULL"

    cost_tracking:
      function: "update_orchestrator_costs (line 379)"
      logic: "Accumulates token usage and USD cost using SQL SET total_cost = total_cost + $value"

    status_update:
      function: "update_orchestrator_status (line 453)"
      logic: "Updates orchestrator status field"

    metadata_update:
      function: "update_orchestrator_metadata (line 480)"
      logic: "Merges JSONB metadata using || operator"

  agent_management:
    create:
      function: "create_agent (line 738)"
      logic: "Creates new command agent under orchestrator"

    get:
      function: "get_agent (line 787)"
      logic: "Retrieve agent by UUID"

    get_by_name:
      function: "get_agent_by_name (line 807)"
      logic: "Retrieve agent by orchestrator_id + name"

    list:
      function: "list_agents (line 835)"
      logic: "List all agents for orchestrator"

    status_update:
      function: "update_agent_status (line 860)"
      logic: "Updates agent status field"

    session_update:
      function: "update_agent_session (line 876)"
      logic: "Updates agent Claude SDK session_id"

    cost_tracking:
      function: "update_agent_costs (line 892)"
      logic: "Accumulates agent token usage and cost"

    reset_tokens:
      function: "reset_agent_tokens (line 923)"
      logic: "Resets token counts to zero (for /compact)"

    delete:
      function: "delete_agent (line 946)"
      logic: "Soft delete agent (sets archived=true)"

  chat_operations:
    insert:
      function: "insert_chat_message (line 523)"
      pattern: "Insert -> Return UUID"

    get_history:
      function: "get_chat_history (line 613)"
      logic: "Retrieves chat messages, sorted by created_at ASC"

    get_turn_count:
      function: "get_turn_count (line 677)"
      logic: "Returns count of chat messages for orchestrator"

    delete_history:
      function: "delete_chat_history (line 706)"
      logic: "Deletes all chat for orchestrator"

  agent_logging:
    insert_hook:
      function: "insert_hook_event (line 965)"
      logic: "Writes hook event to agent_logs"

    insert_block:
      function: "insert_message_block (line 1019)"
      logic: "Writes response block to agent_logs"

    update_summary:
      function: "update_log_summary (line 1073)"
      logic: "Updates agent_logs.summary field"

    update_payload:
      function: "update_log_payload (line 1087)"
      logic: "Merges JSONB payload using || operator"

    get_logs:
      function: "get_agent_logs (line 1146)"
      logic: "Retrieves agent_logs with filtering"

    get_tail:
      function: "get_tail_summaries (line 1205), get_tail_raw (line 1240)"
      logic: "Tail-style retrieval of recent logs"

    get_latest_task:
      function: "get_latest_task_slug (line 1281)"
      logic: "Returns most recent task_slug for agent"

  summary_updates:
    - "update_log_summary (line 1073): Updates agent_logs.summary"
    - "update_chat_summary (line 1104): Updates orchestrator_chat.summary"
    - "update_prompt_summary (line 1118): Updates prompts.summary"
    - "update_system_log_summary (line 1132): Updates system_logs.summary"

  prompt_operations:
    insert:
      function: "insert_prompt (line 1307)"
      logic: "Creates new prompt record"

  system_logging:
    insert:
      function: "insert_system_log (line 1352)"
      logic: "Creates system log entry"

    list:
      function: "list_system_logs (line 1447)"
      logic: "Retrieves system logs with filtering"

  event_stream:
    list_agent_logs:
      function: "list_agent_logs (line 1407)"
      logic: "Gets all agent_logs for orchestrator with JOIN for agent_name"

    get_orchestrator_action_blocks:
      function: "get_orchestrator_action_blocks (line 1508)"
      logic: "Queries system_logs for thinking_block/tool_use_block by orchestrator"

    list_orchestrator_chat:
      function: "list_orchestrator_chat (line 1549)"
      logic: "Gets orchestrator_chat with optional filtering"

  alpaca_sync_operations:
    file: "apps/orchestrator_3_stream/backend/modules/alpaca_sync_service.py"
    note: "Uses separate asyncpg pool, same DATABASE_URL"

    sync_orders:
      function: "sync_orders (line 92)"
      logic: "Fetches fill activities from Alpaca API, assigns trade_ids, persists to DB"
      api: "Uses Alpaca Account Activities API (activity_types=FILL)"

    assign_trade_id:
      function: "_assign_trade_id (line 235)"
      logic: "Groups orders by underlying+expiry, clusters by 5-min time window"

    detect_strategy:
      function: "_detect_strategy (line 301)"
      logic: "Detects iron_condor (4 legs), vertical_spread (2 same type), straddle, strangle"

    persist_orders:
      function: "_persist_orders (line 360)"
      logic: "Upserts to alpaca_orders with ON CONFLICT DO UPDATE"

    sync_positions:
      function: "sync_positions (line 454)"
      logic: "Fetches positions from Alpaca, marks old as closed, upserts new"

    get_trades:
      function: "get_trades (line 676)"
      logic: "Aggregates orders by trade_id, calculates P&L, determines status"
      sql_pattern: "GROUP BY trade_id with SUM for premium/cost calculations"

    get_trade_stats:
      function: "get_trade_stats (line 791)"
      logic: "Computes total_pnl, win_rate, trade counts by status"

    get_orders_by_trade_id:
      function: "get_orders_by_trade_id (line 573)"
      logic: "Retrieves all orders for a specific trade group"

    get_open_positions:
      function: "get_open_positions (line 654)"
      logic: "Retrieves positions WHERE is_open = TRUE"

performance_tuning:
  indexes:
    - "Foreign keys indexed for join performance"
    - "Status columns indexed for filtering active agents"
    - "Timestamp columns indexed (DESC) for chronological sorting"
    - "Partial indexes on nullable fields (WHERE field IS NOT NULL)"
    - "Composite indexes for common query patterns"

  connection_pooling:
    - "Min connections: 5 (prevents cold start latency)"
    - "Max connections: 20 (prevents connection exhaustion)"
    - "Statement preparation enabled by default in asyncpg"

  fetching:
    - "Use 'fetch' for lists, 'fetchrow' for single items, 'fetchval' for scalars"
    - "Pagination via LIMIT/OFFSET"

testing:
  integration_tests:
    file: "apps/orchestrator_3_stream/backend/tests/test_database.py"
    coverage:
      - "Connection lifecycle"
      - "Orchestrator creation/retrieval"
      - "Chat message persistence"
      - "Cost accumulation accuracy"
      - "Session tracking"

best_practices:
  - "Always use UUID objects in Python, let asyncpg handle conversion"
  - "Always use UTC for timestamps (TIMESTAMPTZ)"
  - "Use JSONB for flexible schema needs (metadata, payloads)"
  - "Never store secrets in the database (API keys via env vars)"
  - "Run migrations via run_migrations.py, never manual SQL"
  - "Sync models.py changes immediately to app directories"
  - "Use ON DELETE CASCADE for child records"

known_issues:
  - "No specialized table for file tracking (currently inside agent_logs payload)"
  - "Cost calculation logic duplicated in SQL and Python"
  - "No hard delete (archived flag used, but manual cleanup scripts exist)"
